# 17 — Browser Automation & Visual Testing

> Architecture document — February 2026
> How agents browse, test, verify, and scrape autonomously.

---

## 1. Overview

The browser layer gives agents eyes and hands on the web. It serves four distinct use cases:

1. **E2E Testing** — deterministic smoke tests on every deploy
2. **Visual Regression** — catch UI breakage before users do
3. **Deployment Verification** — autonomous post-deploy health checks
4. **Web Scraping / Market Research** — agents browsing the open web for intelligence

The core stack: **Playwright** (deterministic foundation) + **Stagehand** (AI-driven self-healing) + **Browserbase** (cloud browser infrastructure). Each layer adds capability without replacing the one below it.

---

## 2. Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Agent Orchestrator                       │
│         (requests browser actions via tool API)              │
├─────────────────────────────────────────────────────────────┤
│                    Browser Tool API                          │
│  browse() | test() | screenshot() | extract() | verify()    │
├──────────┬──────────────┬──────────────┬────────────────────┤
│  Coded   │  AI-Driven   │   Visual     │   Data             │
│  Tests   │  Actions     │   Checks     │   Extraction       │
│          │              │              │                     │
│ Playwright│ Stagehand    │ Pixel-diff + │ Stagehand extract  │
│ assertions│ act/observe  │ LLM vision   │ + AgentQL queries  │
├──────────┴──────────────┴──────────────┴────────────────────┤
│                   Browser Runtime                            │
│                                                              │
│   Local: Playwright (headless Chromium)                      │
│   Cloud: Browserbase (managed, stealth, scalable)            │
│   Selection: local for CI, cloud for scraping/stealth        │
└─────────────────────────────────────────────────────────────┘
```

### Runtime Selection Logic

| Scenario | Runtime | Why |
|---|---|---|
| CI pipeline E2E tests | Local Playwright | Fast, free, deterministic |
| Post-deploy verification | Local or Cloud | Local for internal apps, cloud for production URLs |
| Web scraping / market research | Browserbase Cloud | Anti-bot evasion, proxy rotation, CAPTCHA solving |
| Authenticated session reuse | Browserbase Cloud | Persistent contexts across sessions |
| Visual regression in CI | Local Playwright | Consistent rendering environment |

---

## 3. The Three Testing Layers

### 3.1 Deterministic E2E Tests (Playwright)

Standard Playwright tests for known critical paths. These are the foundation — fast, repeatable, CI-friendly.

```typescript
// Generated by coding agent, verified by QA agent
test('checkout flow completes', async ({ page }) => {
  await page.goto('/products');
  await page.click('[data-testid="add-to-cart"]');
  await page.click('[data-testid="checkout"]');
  await page.fill('#email', 'test@example.com');
  await page.click('button:has-text("Pay")');
  await expect(page).toHaveURL(/\/confirmation/);
  await expect(page.locator('.order-id')).toBeVisible();
});
```

**Agent workflow:**
- Coding agent writes/updates Playwright tests alongside feature code
- QA agent (Hawk) reviews tests for coverage gaps, generates adversarial additions
- CI runs on every PR; failures block merge

### 3.2 Self-Healing AI Tests (Stagehand)

Stagehand's killer feature: **cached AI selectors that self-heal when the UI changes**.

```typescript
const stagehand = new Stagehand({
  env: isCI ? 'LOCAL' : 'BROWSERBASE',
  browserbaseApiKey: process.env.BROWSERBASE_API_KEY,
});
await stagehand.init();
await stagehand.page.goto('https://app.example.com');

// First run: AI finds the right element (~2s, costs tokens)
// Subsequent runs: cached selector replay (~50ms, free)
// UI redesign: auto-heals, re-caches
await stagehand.act('click the user profile menu');
await stagehand.act('navigate to billing settings');

const plan = await stagehand.extract(
  'what plan is the user on and when does it renew?',
  z.object({
    plan: z.string(),
    renewalDate: z.string(),
    price: z.string(),
  })
);
```

**When to use Stagehand over raw Playwright:**
- Testing third-party integrations where you don't control the DOM
- Flows that break frequently due to UI changes
- Post-deploy verification of production (selectors may drift between deploys)
- Any test where maintaining selectors is more expensive than the AI overhead

**Caching strategy:**
- Cache stored per-project in `.stagehand-cache/`
- Cache key = action text + URL pattern + page context hash
- Cache invalidation: automatic on selector failure, manual on major redesigns
- CI caches warm from last successful run

### 3.3 Visual Regression

Two complementary approaches:

**Pixel-diff (every PR, in CI):**
```typescript
test('homepage visual regression', async ({ page }) => {
  await page.goto('/');
  await page.waitForLoadState('networkidle');
  await expect(page).toHaveScreenshot('homepage.png', {
    maxDiffPixelRatio: 0.01,
    animations: 'disabled',
  });
});
```

**LLM vision audit (post-deploy, weekly full-site):**
```typescript
async function visualAudit(page: Page, pageName: string): Promise<AuditResult> {
  const screenshot = await page.screenshot({ fullPage: true });
  const result = await llm.analyze({
    image: screenshot,
    prompt: `Audit this web page for visual issues:
      - Broken layouts or overlapping elements
      - Missing images or icons (broken img tags)
      - Text overflow or truncation
      - Inconsistent spacing or alignment
      - Error states shown to users
      - Empty sections that should have content
      Report each issue with severity (critical/warning/info).`,
    schema: z.object({
      issues: z.array(z.object({
        severity: z.enum(['critical', 'warning', 'info']),
        description: z.string(),
        location: z.string(),
      })),
      overallScore: z.number().min(0).max(100),
    }),
  });
  return result;
}
```

**Visual testing pipeline:**
```
PR merge → Deploy to staging
  → Pixel-diff against golden screenshots (auto, blocks deploy)
  → LLM visual audit of key pages (async, reports to channel)
  → If critical issues: block production deploy, alert team
  → If clean: promote to production
  → Post-production deploy: LLM audit again (smoke check)
```

---

## 4. Deployment Verification Pipeline

Runs automatically after every deployment:

```
Deploy completes → Health check (HTTP 200 on /health, /api/status)
  │
  ├─ FAST (< 30s): Endpoint health, critical API responses
  │
  ├─ MEDIUM (< 3min): Playwright smoke tests
  │   • Login flow
  │   • Core CRUD operations
  │   • Payment page loads
  │
  ├─ DEEP (< 10min): Stagehand exploratory
  │   • Navigate all main sections
  │   • Extract key data, verify not empty/error
  │   • Check for console errors
  │
  └─ VISUAL (async): LLM screenshot audit
      • Capture key pages
      • Compare with pre-deploy baselines
      • Report anomalies

  → All clear: mark deploy as stable
  → Critical failure: auto-rollback, alert team
  → Warning: flag for review, don't rollback
```

### Rollback Decision Matrix

| Signal | Severity | Action |
|---|---|---|
| Health endpoint down | Critical | Immediate rollback |
| Login flow broken | Critical | Immediate rollback |
| Smoke test failure | High | Rollback if >1 test fails |
| Visual regression (critical) | Medium | Alert, hold; manual decision |
| Console errors spike | Medium | Alert, investigate |
| LLM audit warnings | Low | Log, review next day |

---

## 5. Autonomous Web Browsing for Agents

### Use Cases
- **Market research**: competitor pricing, feature comparison, trend analysis
- **Content gathering**: documentation, API references, changelog monitoring
- **Verification**: check that marketing site matches product reality
- **Data enrichment**: company info, social profiles, public data

### Agent Browse Tool

```typescript
interface BrowseTool {
  // Navigate and extract structured data
  browse(params: {
    url: string;
    task: string;           // "find the pricing for their pro plan"
    schema?: ZodSchema;     // structured output shape
    maxPages?: number;      // limit crawl depth
    timeout?: number;       // ms
  }): Promise<ExtractedData>;

  // Take action on a page (fill forms, click, navigate)
  act(params: {
    sessionId: string;      // reuse existing session
    action: string;         // natural language action
  }): Promise<ActionResult>;

  // Capture visual state
  screenshot(params: {
    url: string;
    fullPage?: boolean;
    selector?: string;      // screenshot specific element
  }): Promise<Buffer>;

  // Run a test suite against a URL
  test(params: {
    url: string;
    suite: string;          // test suite name or inline tests
    visual?: boolean;       // include visual regression
  }): Promise<TestResults>;

  // Monitor a page for changes
  watch(params: {
    url: string;
    selector?: string;      // what to watch
    interval: number;       // check frequency (ms)
    onChange: (diff: Diff) => void;
  }): Promise<WatchHandle>;
}
```

### Session & Auth Management

```
┌─────────────────────────────────────────┐
│           Session Vault                  │
│                                          │
│  Encrypted credential store:             │
│  • OAuth tokens (per-service)            │
│  • Cookie jars (serialized)              │
│  • Browser storage state (Playwright)    │
│  • API keys for authenticated scraping   │
│                                          │
│  Access control:                         │
│  • Agent role → permitted domains        │
│  • Audit log of all credential use       │
│  • Auto-rotate tokens on expiry          │
│  • No credential in agent memory/logs    │
└─────────────────────────────────────────┘
```

**Auth patterns:**

| Pattern | Implementation | Use Case |
|---|---|---|
| Saved storage state | `browserContext.storageState()` → encrypted file → `newContext({ storageState })` | Internal apps with session cookies |
| OAuth token injection | Fetch token via OAuth flow, inject as header/cookie | API-authenticated SPAs |
| Persistent Browserbase context | Browserbase persistent sessions with saved cookies | Long-running monitoring |
| Service account login | Playwright automates login flow, saves state | Third-party SaaS tools |

**Key rules:**
1. Credentials never appear in agent prompts, logs, or memory
2. Each agent role has an allow-list of domains it can authenticate to
3. All authenticated browsing is audit-logged (URL, timestamp, agent, action)
4. Sessions auto-expire; re-auth is automated but logged
5. Browser storage state files encrypted at rest with per-agent keys

### Anti-Bot & Stealth

For scraping external sites, stealth is essential. Browserbase handles most of this:

- **Fingerprint rotation**: randomized browser fingerprints (canvas, WebGL, fonts)
- **Residential proxies**: IP rotation per-session or per-request
- **CAPTCHA solving**: managed CAPTCHA interception (reCAPTCHA, hCaptcha, Cloudflare Turnstile)
- **Human-like behavior**: randomized delays, mouse movements, scroll patterns
- **Header normalization**: consistent accept, language, encoding headers

**When Browserbase isn't needed** (internal apps, public APIs):
- Use local Playwright with default settings
- No stealth overhead, faster execution, zero cost

**Rate limiting & politeness:**
- Per-domain rate limits (configurable, default 1 req/2s)
- Respect `robots.txt` unless explicitly overridden (with justification logged)
- Exponential backoff on 429/503 responses
- Circuit breaker: stop scraping a domain after N consecutive failures

---

## 6. Browser Tool API Surface

The unified API that agents call. Implemented as an MCP tool server.

### Core Tools

```yaml
tools:
  browser.navigate:
    description: "Open a URL in a browser session"
    params:
      url: string (required)
      sessionId?: string        # reuse existing session
      runtime?: local | cloud   # default: auto-select
      stealth?: boolean         # enable anti-detection
      storageState?: string     # auth state to inject
    returns:
      sessionId: string
      title: string
      url: string               # final URL after redirects

  browser.act:
    description: "Perform an action on the current page (AI-driven)"
    params:
      sessionId: string (required)
      action: string (required)  # natural language: "click the sign up button"
    returns:
      success: boolean
      description: string       # what happened

  browser.extract:
    description: "Extract structured data from the current page"
    params:
      sessionId: string (required)
      instruction: string (required)  # "get all product names and prices"
      schema?: object            # JSON schema for output shape
    returns:
      data: object              # extracted data matching schema

  browser.screenshot:
    description: "Capture a screenshot of the current page"
    params:
      sessionId: string (required)
      fullPage?: boolean
      selector?: string         # specific element
    returns:
      image: base64string
      width: number
      height: number

  browser.test:
    description: "Run E2E tests against a URL"
    params:
      url: string (required)
      tests: string[]           # test file paths or inline test descriptions
      visual?: boolean          # include visual regression
      report?: boolean          # generate HTML report
    returns:
      passed: number
      failed: number
      results: TestResult[]
      reportUrl?: string

  browser.visual_diff:
    description: "Compare current page against a baseline screenshot"
    params:
      sessionId: string (required)
      baseline: string          # path to baseline image
      threshold?: number        # max pixel diff ratio (default 0.01)
    returns:
      match: boolean
      diffPercentage: number
      diffImage?: base64string

  browser.observe:
    description: "List available actions on the current page"
    params:
      sessionId: string (required)
    returns:
      actions: string[]         # available interactions

  browser.close:
    description: "Close a browser session"
    params:
      sessionId: string (required)
```

### Session Lifecycle

```
Agent calls browser.navigate(url)
  → System selects runtime (local vs cloud)
  → Returns sessionId
  → Agent calls browser.act / browser.extract / browser.screenshot
  → Agent calls browser.close(sessionId)
  → Session recorded for audit

Timeout: sessions auto-close after 5 minutes of inactivity
Max duration: 30 minutes per session (configurable)
Max concurrent: 5 per agent (prevents resource exhaustion)
```

---

## 7. Integration with CI/CD & Hawk QA Agent

### CI Pipeline Integration

```yaml
# .github/workflows/deploy-verify.yml
deploy-verify:
  runs-on: ubuntu-latest
  steps:
    - name: Deploy to staging
      run: ./deploy.sh staging

    - name: Browser smoke tests
      run: npx playwright test --project=smoke
      env:
        BASE_URL: ${{ steps.deploy.outputs.url }}

    - name: Stagehand verification
      run: node scripts/stagehand-verify.js
      env:
        BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
        TARGET_URL: ${{ steps.deploy.outputs.url }}

    - name: Visual regression
      run: npx playwright test --project=visual
      env:
        BASE_URL: ${{ steps.deploy.outputs.url }}

    - name: Report results
      if: failure()
      run: node scripts/notify-failure.js
```

### Hawk QA Agent Browser Capabilities

Hawk uses the browser tool API for:

1. **Post-deploy verification** — autonomously browses deployed app, runs smoke tests, reports issues
2. **Visual regression review** — when pixel-diff flags a change, Hawk uses LLM vision to determine if it's intentional or a bug
3. **Exploratory testing** — Stagehand-driven exploration of new features, looking for edge cases
4. **Cross-browser verification** — runs critical flows in Chromium, Firefox, WebKit via Playwright

### Test Artifact Storage

```
/test-results/
  ├── screenshots/
  │   ├── baseline/           # golden screenshots
  │   └── runs/
  │       └── 2026-02-08/
  │           ├── homepage.png
  │           ├── homepage-diff.png
  │           └── results.json
  ├── traces/                 # Playwright trace files
  ├── reports/                # HTML test reports
  └── stagehand-cache/        # cached AI selectors
```

---

## 8. Web Scraping Architecture

For market research and competitive intelligence:

```
┌──────────────────────────────────────────┐
│           Scraping Orchestrator           │
│  • Job queue (scrape requests from agents)│
│  • Rate limiter per domain                │
│  • Result cache (avoid re-scraping)       │
├──────────────────────────────────────────┤
│           Browserbase Pool                │
│  • N concurrent browser sessions          │
│  • Auto-proxy rotation                    │
│  • CAPTCHA solving                        │
│  • Session recycling                      │
├──────────────────────────────────────────┤
│           Data Pipeline                   │
│  • Raw HTML → structured extraction       │
│  • Stagehand extract() or AgentQL         │
│  • Validation against expected schema     │
│  • Dedup + storage                        │
└──────────────────────────────────────────┘
```

**Scraping ethics & compliance:**
- Only scrape publicly accessible data
- Respect rate limits and robots.txt by default
- No scraping behind paywalls without authorization
- Data retention policies: purge raw HTML after extraction
- GDPR: no PII collection without explicit purpose

---

## 9. Cost Model

| Component | Cost Driver | Estimate |
|---|---|---|
| Local Playwright | Compute (CI minutes) | ~$0.01/test run |
| Browserbase | Per browser-minute | ~$0.01–0.05/min |
| Stagehand AI calls | LLM tokens (first run + cache miss) | ~$0.01–0.10/action |
| LLM visual audit | Vision model tokens | ~$0.05–0.15/page |
| Screenshot storage | S3/R2 | Negligible |

**Cost optimization:**
- Stagehand caching eliminates 90%+ of AI calls after warm-up
- Visual audits only on deploy (not every PR) — pixel-diff is free
- Browserbase only for external/stealth needs — local for everything else
- Batch scraping jobs to reuse sessions

---

## 10. Implementation Phases

### Phase 1: Foundation (Week 1–2)
- [ ] Set up Playwright test infrastructure with CI integration
- [ ] Implement `browser.navigate`, `browser.screenshot`, `browser.close` tools
- [ ] Basic visual regression with Playwright `toHaveScreenshot()`
- [ ] Deploy verification script (health check + smoke tests)

### Phase 2: AI Layer (Week 3–4)
- [ ] Integrate Stagehand for self-healing tests
- [ ] Implement `browser.act`, `browser.extract`, `browser.observe` tools
- [ ] Browserbase integration for cloud browser runtime
- [ ] Session vault for credential management

### Phase 3: Intelligence (Week 5–6)
- [ ] LLM visual audit pipeline
- [ ] Hawk QA agent browser integration
- [ ] Scraping orchestrator with rate limiting and caching
- [ ] `browser.test` and `browser.visual_diff` composite tools

### Phase 4: Production (Week 7–8)
- [ ] Auto-rollback on deployment verification failure
- [ ] Full CI/CD pipeline integration
- [ ] Monitoring dashboard (test pass rates, visual regression trends, scrape success)
- [ ] Cost tracking and optimization

---

## 11. Key Decisions

| Decision | Choice | Rationale |
|---|---|---|
| Base framework | Playwright | Best multi-browser support, built-in visual testing, Stagehand builds on it |
| AI browser layer | Stagehand | Caching model = AI flexibility without ongoing cost; TypeScript-native |
| Cloud browsers | Browserbase | Stagehand's parent company, tight integration, stealth built-in |
| Visual regression (CI) | Playwright pixel-diff | Free, deterministic, fast |
| Visual regression (deep) | LLM vision | Catches semantic issues pixel-diff misses |
| Data extraction | Stagehand extract + AgentQL | Stagehand for interactive pages, AgentQL for complex structured extraction |
| Session management | Playwright storage state + Browserbase persistent contexts | Covers both local and cloud runtimes |
| Tool exposure | MCP server | Agents call browser tools via standard MCP protocol |

---

## 12. Risks & Mitigations

| Risk | Impact | Mitigation |
|---|---|---|
| Stagehand cache staleness | Tests pass on stale cached selectors, miss real bugs | Periodic cache invalidation; run cache-cold tests weekly |
| LLM visual judgment unreliable | False positives/negatives in visual audits | Use as advisory layer, not blocking gate; pixel-diff for blocking |
| Browserbase cost at scale | Expensive if scraping volume grows | Cache aggressively; use local Playwright where stealth isn't needed |
| Anti-bot arms race | Scrapers blocked despite stealth | Browserbase handles this; fallback to API-based data sources |
| Credential leakage | Auth tokens in logs or agent memory | Vault-only access; never pass credentials through agent prompts |
| Flaky E2E tests | CI pipeline unreliable | Playwright auto-wait + retry; Stagehand self-healing; quarantine flaky tests |
